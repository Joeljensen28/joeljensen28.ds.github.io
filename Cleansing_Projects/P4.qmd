---
title: "Client Report - Can You Predict That?"
subtitle: "Course DS 250"
author: "Joel Jensen"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
#| label: libraries
#| include: false
import plotly.express as px

from types import GeneratorType
import pandas as pd
import numpy as np
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
```


## Elevator pitch
_Do you want to know if your home has asbestos in it? You should. Thankfully, the state of Colorado has outlawed the use of asbestos in paint since the year 1980, so if your home is in Colorado and built after that period, you should be good. But what if you don't know when your home was built? Should you be worried? That's where this report comes in handy; we have developed a machine learning model that can classify with striking accuracy whether or not your home was built before 1980!_

```{python}
#| label: Datasets used
#| code-summary: Read and format project data
# These are the datasets that were used:
denver = pd.read_csv("https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_denver/dwellings_denver.csv") #original dataset
ml = pd.read_csv("https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv") #denver dataset rearranged for machine learning with neighborhoods removed due to their excessive number
neighborhoods = pd.read_csv("https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_neighborhoods_ml/dwellings_neighborhoods_ml.csv") #neighborhoods from original dataset assorted into their own dataset for machine learning
nbhd_ml = ml.merge(
    right=neighborhoods,
    how='left',
    on='parcel'
)#merging of ml and neighborhoods
```

## What features can help us determine if a house was built before 1980?

__Here's a few we initially settled on:__

_The first feature that stuck out to us was the neighborhood each house belonged to, as neighborhoods often have a tendency to contain houses built from similar time periods. So to start off, we plotted the percentage of homes that were built before 1980 in each neighborhood._

```{python}
#| label: Homes in Neighborhoods
#| code-summary: Read and format data
# Include and execute your code here
#Find out how many homes are in each neighborhood
nbhd_agg = denver.groupby("nbhd").agg(
    total_homes = ("parcel", "count")
)
#Find out how many homes were built before 1980 in each neighborhood
nbhd_pre_1980 = denver.query(
    "yrbuilt <= 1980"
).groupby(
    "nbhd"
).size().rename(
    "homes_pre_1980", inplace=True
)
#Merge the two tables
neighborhood_metrics = nbhd_agg.merge(
    nbhd_pre_1980, 
    left_index=True, 
    right_index=True, 
    how="left"
).assign( #Create new column calculating the percent of homes built before 1980 in each neighborhood
    pct_pre_1980 = lambda x: round(((nbhd_pre_1980 / x.total_homes) * 100), 2)
)
#Clean up data
neighborhood_metrics.fillna(0, inplace=True)
#Fix index so it is readable by px
neighborhood_metrics.reset_index(inplace=True)
#make sample as 900 is too many to show on a plot
sample = neighborhood_metrics.query("nbhd >= 902 & nbhd <=906")

px.bar(
    sample,
    x="nbhd",
    y="pct_pre_1980",
    labels={'pct_pre_1980': '% of Homes',
            'nbhd': 'Neighborhood'},
    title='Percent of Homes Built Before 1980 by Neighborhood',
    text_auto=True
)
```

_Note that we limited this chart to a few neighborhoods, as the data included more than 900. Each number is a unique identifier for a neighborhood. From this chart we can see that neighborhood may actually be an incredibly useful feature to determining whether it was built before 1980 (for example, if it was built in neighborhood 904, there's nearly a 100% chance that it was, but if it was built in 903, there's only a 10% chance it was)._

_Another feature we thought might be helpful was the quality of the homes. Older homes might be prone to have lower quality due to wear and tear._

```{python}
#| label: Homes by Quality
#| code-summary: plot example
#| fig-align: center

#Find out how many homes there are of each condition
cond_agg = denver.query('condition !="Fair"').groupby("condition").agg(
    total_homes = ("parcel", "count")
)
#Find out how many homes were built before 1980 for each condition
cond_pre_1980 = denver.query(
    "yrbuilt <= 1980 & condition != 'Fair'"
).groupby(
    "condition"
).size().rename(
    "homes_pre_1980", inplace=True
)
#Merge the two tables
condition_metrics = cond_agg.merge(
    cond_pre_1980, 
    left_index=True, 
    right_index=True, 
    how="left"
).assign( #Create new column calculating the percent of homes built before 1980 in each neighborhood
    pct_pre_1980 = lambda x: round(((cond_pre_1980 / x.total_homes) * 100), 2)
)
#Clean up data
condition_metrics.fillna(0, inplace=True)
#fix index
condition_metrics.reset_index(inplace=True)

px.bar(
    condition_metrics,
    x='condition',
    y='pct_pre_1980',
    labels={'pct_pre_1980': '% of Homes',
            'condition': 'Condition'},
    text_auto=True,
    title='Percent of Homes Built Before 1980 by Condition'
)
```

_This chart came to a bit of a surprise for us, as it appears that a significat percentage of homes in the "good" and "very good" categories were built before 1980._

## How accurate is the model?

__96% accurate!__

_As you can see, the model correctly predicted 96% of the test data as being built before or after 1980. If you're interested in the technical know-how of this model, you can expand the code below._

```{python}
#| label: MLM
#| code-summary: Read and format data
features = ['livearea', 'basement', 'arcstyle_ONE AND HALF-STORY',
       'stories', 'nocars', 'numbaths', 'sprice', 'qualified_U',
       'netprice', 'tasp', 'condition_AVG', 'arcstyle_MIDDLE UNIT',
       'quality_B', 'quality_C', 'condition_Good', 'qualified_Q',
       'gartype_Att', 'smonth', 'condition_VGood',
       'gartype_Det', 'numbdrm', 'syear', 'gartype_None',
       'arcstyle_ONE-STORY', 'deduct', 'quality_A',
       'arcstyle_TWO-STORY', 'totunits', 'arcstyle_END UNIT',
       'status_I', 'status_V', 'finbsmnt']

def find_nonfeatures(dataframe, feat_list):
    """
    Built to loop through the unmerged ml dataframe
    and find featuers that were previously determined 
    to not be useful to the model and return those features
    to a list that can be used in a .drop() method, making
    the merge between neighborhoods and ml seamless.
        Parameter 1: the original unmerged ml dataframe
        Parameter 2: a list of previously determined useful features
    """
    #list which nonfeatures will be appended to
    nonfeatures = []
    #loop through each feature in dataframe
    for key in dataframe:
        #determine if the feature is useful
        if key not in feat_list:
            #if not, append it to the list of nonfeatures
            nonfeatures.append(key)
    return nonfeatures
#find nonfeatures to drop from the merged dataframe
nonfeatures = find_nonfeatures(ml, features)
#drop nonfeatures
clean_ml = nbhd_ml.drop(
    columns=nonfeatures
)

#establish features
x = clean_ml
#establish target
y = nbhd_ml.before1980
#split the dataset for training and testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .20, random_state = 777)

# Create a random forest
classifier_RF = RandomForestClassifier()
# Fit the random forest
classifier_RF.fit(x_train, y_train)

# Test the random forest (make classifications)
y_predicted_RF = classifier_RF.predict(x_test)
accuracy = metrics.accuracy_score(y_test, y_predicted_RF)

# Evaluate the random forest accuracy
print("Accuracy:", accuracy)
```

_The algorithm we settled on was a random forest, which generates several decision trees and chooses the classification that the majority of the decision trees agree upon. We also tried using a regular decision tree, gradient boosting classifier, and a support vector machine, but these algorithms had significantly lower accuracy in this case. The features we chose were carefully selected by analyzing which ones had the greatest impact on the accuracy. More on that below._

## What wound up being the most important features?

_Our final model wound up employing well over 30 features (930, if you count each neighborhood, but for the sake of simplicity we will consider neighborhoods to be one feature), but here are the top 5 most important ones:_

```{python}
#| label: Most important features
#| code-summary: Read and format data
#make a df with the most important features
feature_df = pd.DataFrame({'features':x.columns, 'importance':classifier_RF.feature_importances_})
feature_df.sort_values(by='importance', ascending=False, ignore_index=True, inplace=True)
feature_df.head()
```

_And here is a visualization of the same:_

```{python}
#| label: Most important features chart
#| code-summary: Read and format data
px.bar(
    feature_df.head(),
    x='features',
    y='importance',
    labels={'features': 'Features',
            'importance': 'Importance Value'},
    text_auto=True
)
```

_The labels don't make much sense, so here's a description of each one:_

_Stories: The number of stories on the house_

_arcstyle\_ONE-STORY: Tells us the house has one story (very similar to the previous one)_

_numbaths: The number of bathrooms_

_livearea: Liveable square footage_

_tasp: Tax assesed selling price_

## How else can we measure the quality of this model?

__There's a lot of ways.__

_One of the ways we can measure its quality is with something known as a "confusion matrix", which essentially tells us how many times it predicted correctly and incorrectly in both the positive and negative._

```{python}
#| label: Confusion matrix
#| code-summary: Read and format data
#make confusion matrix
confusion = metrics.confusion_matrix(y_test, y_predicted_RF)
#grab the data for conufsion matrix and store in variables
tp = confusion[0][0]
fn = confusion[0][1]
fp = confusion[1][0]
tn = confusion[1][1]
#make confusion matrix more legible
conf_matrix = pd.DataFrame({'': ['True', 'False'], 
                                 'Positive': [tp, fp], 
                                 'Negative': [tn, fn]})
#hide index on dataframe
conf_matrix.style.hide()
```

_Here we can see that the table is assorted into true negatives (correctly predicted a house being built after 1980), true positives (correctly predicted a house being built before 1980), false negatives (incorrectly predicted a house being built after 1980), and false positives (incorrectly predicted a house being built before 1980)._

_A few helpful metrics can be obtained from this matrix, including the precision of the model, and the negative predictive value (NPV). Accuracy itself is also determined through a confusion matrix:_

```{python}
#| label: metrics
#calculate precision score
precision = tp / (tp + fp)
#calculate negative predictive value
npv = tn / (tn + fn)
#create table with the metrics
ml_metrics = pd.DataFrame({'Precision': [precision],
                           'NPV': [npv],
                           'Accuracy': [accuracy]})
#hide the index so it's more aesthetically appealing
ml_metrics.style.hide()
```

_The precision is calculated by taking the number of true positives and dividing it by the number of true positive plus the number of false positives. It tells us how often it correctly predicts a positive result._
_The NPV is the inverse of the precision as it tells us how often it correctly predicts a negative result. It is calculated by taking the number of true negatives divided by the number of true negatives plus true positives._
_Accuracy is determined by taking the total number of true predictions and dividing it by the number of predictions made, true or false._

_From these metrics we can see that the model is slightly better at predicting negative values than positive ones._

## Conclusion

_In conclusion, this model can predict whether or not a house was built before 1980 with great accuracy. By applying this model we can confidently determine if a house is at risk of containing asbestos._